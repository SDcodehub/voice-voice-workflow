{{- if .Values.llmService.enabled }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "voice-workflow.fullname" . }}-llm-service-config
  namespace: {{ include "voice-workflow.namespace" . }}
  labels:
    {{- include "voice-workflow.labels" . | nindent 4 }}
    app.kubernetes.io/component: llm-service
data:
  LLM_SERVICE_NAME: "llm-service"
  LLM_SERVICE_HOST: "0.0.0.0"
  LLM_HTTP_PORT: "{{ .Values.llmService.service.httpPort }}"
  LLM_SERVICE_PORT: "{{ .Values.llmService.service.grpcPort }}"
  LLM_LLM_BACKEND: "{{ .Values.llmService.config.backend }}"
  LLM_NIM_API_URL: "{{ include "voice-workflow.nimLlmUrl" . }}"
  LLM_NIM_MODEL: "{{ .Values.llmService.config.model }}"
  LLM_MAX_TOKENS: "{{ .Values.llmService.config.maxTokens }}"
  LLM_TEMPERATURE: "{{ .Values.llmService.config.temperature }}"
  LLM_TOP_P: "{{ .Values.llmService.config.topP }}"
  LLM_REDIS_HOST: "{{ include "voice-workflow.redisHost" . }}"
  LLM_REDIS_PORT: "6379"
  LLM_REDIS_DB: "1"
  LLM_ENABLE_CACHE: "{{ .Values.llmService.config.enableCache }}"
  LLM_CACHE_TTL_SECONDS: "{{ .Values.llmService.config.cacheTtlSeconds }}"
  LLM_MAX_HISTORY_TURNS: "{{ .Values.llmService.config.maxHistoryTurns }}"
  {{- if .Values.observability.tracing.enabled }}
  LLM_OTLP_ENDPOINT: "{{ .Values.observability.tracing.otlpEndpoint }}"
  LLM_ENABLE_TRACING: "true"
  {{- end }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "voice-workflow.fullname" . }}-llm-service
  namespace: {{ include "voice-workflow.namespace" . }}
  labels:
    {{- include "voice-workflow.labels" . | nindent 4 }}
    app.kubernetes.io/component: llm-service
spec:
  replicas: {{ .Values.llmService.replicas }}
  selector:
    matchLabels:
      {{- include "voice-workflow.selectorLabels" . | nindent 6 }}
      app.kubernetes.io/component: llm-service
  template:
    metadata:
      labels:
        {{- include "voice-workflow.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: llm-service
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "{{ .Values.llmService.service.httpPort }}"
        prometheus.io/path: "/metrics"
    spec:
      {{- include "voice-workflow.imagePullSecrets" . | nindent 6 }}
      containers:
        - name: llm-service
          image: "{{ .Values.llmService.image.repository }}:{{ .Values.llmService.image.tag }}"
          imagePullPolicy: {{ .Values.llmService.image.pullPolicy }}
          ports:
            - containerPort: {{ .Values.llmService.service.httpPort }}
              name: http
            - containerPort: {{ .Values.llmService.service.grpcPort }}
              name: grpc
          envFrom:
            - configMapRef:
                name: {{ include "voice-workflow.fullname" . }}-llm-service-config
          env:
            {{- if and .Values.ngc.apiKey (not .Values.ngc.existingSecret) }}
            - name: LLM_NIM_API_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ include "voice-workflow.fullname" . }}-llm-secrets
                  key: ngc-api-key
            {{- else if .Values.ngc.existingSecret }}
            - name: LLM_NIM_API_KEY
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.ngc.existingSecret }}
                  key: ngc-api-key
                  optional: true
            {{- end }}
          resources:
            {{- toYaml .Values.llmService.resources | nindent 12 }}
          livenessProbe:
            httpGet:
              path: /health
              port: {{ .Values.llmService.service.httpPort }}
            initialDelaySeconds: 10
            periodSeconds: 15
          readinessProbe:
            httpGet:
              path: /ready
              port: {{ .Values.llmService.service.httpPort }}
            initialDelaySeconds: 5
            periodSeconds: 5
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app.kubernetes.io/component
                      operator: In
                      values:
                        - llm-service
                topologyKey: kubernetes.io/hostname
---
apiVersion: v1
kind: Service
metadata:
  name: {{ include "voice-workflow.fullname" . }}-llm-service
  namespace: {{ include "voice-workflow.namespace" . }}
  labels:
    {{- include "voice-workflow.labels" . | nindent 4 }}
    app.kubernetes.io/component: llm-service
spec:
  type: {{ .Values.llmService.service.type }}
  ports:
    - port: {{ .Values.llmService.service.httpPort }}
      targetPort: {{ .Values.llmService.service.httpPort }}
      name: http
    - port: {{ .Values.llmService.service.grpcPort }}
      targetPort: {{ .Values.llmService.service.grpcPort }}
      name: grpc
  selector:
    {{- include "voice-workflow.selectorLabels" . | nindent 4 }}
    app.kubernetes.io/component: llm-service
{{- end }}

